{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Imports and requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* В данном соревновании мы имеем дело с последовательностями, один из интуитивных способов работы с ними &ndash; использование рекуррентных нейронных сетей. В этом базовом решении мы демонстрируем, как можно построить хорошее решение задачи соревнования без использования сложного и трудоемкого feature engineering'а (чтобы эффективно решать ту же задачу с высоким качеством с помощью бустингов нужно несколько тысяч признаков), благодаря рекуррентным нейронным сетям. В этом ноутбуке мы построим решение с использованием фреймфорка `torch`. Для комфортной работы Вам понадобится машина с `GPU` (хватит ресурсов `google colab` или `kaggle`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tqdm\n",
    "\n",
    "# !!! измените \"2\" на номер доступной вам сuda\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# добавим родительскую директорию, в ней лежат все необходимые полезные функции для обработки данных\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"seaborn-pastel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_PATH = \"../data/train_data/\"\n",
    "TEST_DATA_PATH = \"../data/test_data/\"\n",
    "\n",
    "TRAIN_TARGET_PATH = \"../data/train_target.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999995</th>\n",
       "      <td>2999995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999996</th>\n",
       "      <td>2999996</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999997</th>\n",
       "      <td>2999997</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999998</th>\n",
       "      <td>2999998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999999</th>\n",
       "      <td>2999999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  flag\n",
       "0              0     0\n",
       "1              1     0\n",
       "2              2     0\n",
       "3              3     0\n",
       "4              4     0\n",
       "...          ...   ...\n",
       "2999995  2999995     0\n",
       "2999996  2999996     0\n",
       "2999997  2999997     0\n",
       "2999998  2999998     0\n",
       "2999999  2999999     0\n",
       "\n",
       "[3000000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target = pd.read_csv(TRAIN_TARGET_PATH)\n",
    "train_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Как и в случае с бустингами, мы не можем поместить всю выборку в память ввиду, например, ограниченных ресурсов. Для итеративного чтения данных нам потребуется функция `utils.read_parquet_dataset_from_local`, которая читает N частей датасета за раз в память.\n",
    "\n",
    "\n",
    "* Нейронные сети требуют отдельного внимания к тому, как будут предобработаны и поданы данные. Важные моменты, на которые требуется обратить внимание:\n",
    "    1. Использование рекуррентных сетей подразумевает работу на уровне последовательностей, где одна последовательность &ndash; все исторические кредиты клиента. Чтобы преобразовать `pd.DataFrame` с записями из кредитных историй клиентов в табличном виде к последовательностям, мы подготовили функцию `dataset_preprocessing_utils.transform_credits_to_sequences`, она производит необходимые манипуляции и возвращает фрейм с двумя колонками: `id` и `sequences`. Колонка `sequences` представляет из себя список списков длины `len(features)`, где каждый вложенный список &ndash; значения одного конкретного признака во всех кредитах клиента. \n",
    "    \n",
    "    2. Клиенты могут иметь различные по длине кредитные истории. При этом обучение нейронных сетей происходит батчами и поскольку рекуррентные слои не способны обрабатывать батчи с последовательностями  неодинаковой длины, существует несколько подходов для приведения последовтельностей в батче к удобоваримому виду. Простой подход заключается в дополнении более коротких последовательностей нулями до максимальной длины последовательности в батче (т. н. паддинг). Довольно неэффективно делать паддинг внутри батча на последовательностях случайной длины (часто будем делать большой и бесполезный паддинг). Гораздо лучше использовать технику `Sequence Bucketing` (о ней мы рассказываем в нашем треке). Для реализации паддинга последовательностей кредитов клиентов мы подготовили функцию `dataset_preprocessing_utils.create_padded_buckets`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import read_parquet_dataset_from_local\n",
    "from dataset_preprocessing_utils import features, transform_credits_to_sequences, create_padded_buckets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* В дальнейшем при построении рекуррентной нейронной сети нам понадобятся следующие статистики по тренировочной и тестовой выборкам: распределение длин кредитных историй и число уникальных значений каждого категориального значения. Посчитаем эти статистики:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "413ff584088a4ad8a0bf681945cae874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Count statistics on train data:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunks:\n",
      "../data/train_data/train_data_0.pq\n",
      "../data/train_data/train_data_1.pq\n",
      "../data/train_data/train_data_2.pq\n",
      "../data/train_data/train_data_3.pq\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e419f7ab17724ca8aa6a7276c6ecd90d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading dataset with pandas:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunks:\n",
      "../data/train_data/train_data_4.pq\n",
      "../data/train_data/train_data_5.pq\n",
      "../data/train_data/train_data_6.pq\n",
      "../data/train_data/train_data_7.pq\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eef5135bcb5b4e3cb1b53f5187a3cb21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading dataset with pandas:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunks:\n",
      "../data/train_data/train_data_8.pq\n",
      "../data/train_data/train_data_9.pq\n",
      "../data/train_data/train_data_10.pq\n",
      "../data/train_data/train_data_11.pq\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86c22115425748578d52faa4186db3f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading dataset with pandas:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb2c426e7c974a14ac2f0f8b4824fbcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Count statistics on test data:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunks:\n",
      "../data/test_data/test_data_0.pq\n",
      "../data/test_data/test_data_1.pq\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e7a79cc1125474499969d76fa94a040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading dataset with pandas:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 5s, sys: 39.5 s, total: 1min 44s\n",
      "Wall time: 53.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "train_lens = []\n",
    "test_lens = []\n",
    "uniques = defaultdict(set)\n",
    "\n",
    "for step in tqdm.notebook.tqdm(range(0, 12, 4),\n",
    "                     desc=\"Count statistics on train data\"):\n",
    "        credits_frame = read_parquet_dataset_from_local(TRAIN_DATA_PATH, step, 4, verbose=True)\n",
    "        seq_lens = credits_frame.groupby(\"id\").agg(seq_len=(\"rn\", \"max\"))[\"seq_len\"].values\n",
    "        train_lens.extend(seq_lens)\n",
    "        credits_frame.drop(columns=[\"id\", \"rn\"], inplace=True)\n",
    "        for feat in credits_frame.columns.values:\n",
    "            uniques[feat] = uniques[feat].union(credits_frame[feat].unique())\n",
    "train_lens = np.hstack(train_lens)\n",
    "\n",
    "for step in tqdm.notebook.tqdm(range(0, 2, 2),\n",
    "                     desc=\"Count statistics on test data\"):\n",
    "        credits_frame = read_parquet_dataset_from_local(TEST_DATA_PATH, step, 2, verbose=True)\n",
    "        seq_lens = credits_frame.groupby(\"id\").agg(seq_len=(\"rn\", \"max\"))[\"seq_len\"].values\n",
    "        test_lens.extend(seq_lens)\n",
    "        credits_frame.drop(columns=[\"id\", \"rn\"], inplace=True)\n",
    "        for feat in credits_frame.columns.values:\n",
    "            uniques[feat] = uniques[feat].union(credits_frame[feat].unique())\n",
    "test_lens = np.hstack(test_lens)\n",
    "uniques = dict(uniques)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Чтобы сразу убедиться, что посчитанные статистики интересные и полезные, построим графики распределений длин кредитных историй в тренировочной и тестовой выборках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "train_len_counter = pd.Series(Counter(train_lens)).sort_index()\n",
    "test_len_counter = pd.Series(Counter(test_lens)).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 54 artists>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 6), nrows=1)\n",
    "ax.bar(train_len_counter.index.values, train_len_counter.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 50 artists>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 6), nrows=1)\n",
    "ax.bar(test_len_counter.index.values, test_len_counter.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58, 57)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lens.max(), test_lens.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Один из аргументов в функции `dataset_preprocessing_utils.create_padded_buckets` &ndash; `bucket_info` &ndash; словарь, где для конкретной длины последовательности указано до какой длины нужно делать паддинг. Для данного бэйзлайна возьмем простое разбиение на 43 бакета: \n",
    "| Длина последовательности | Длина после паддинга |\n",
    "| :-: | :-: \n",
    "| 1 &ndash; 40 | без изменений |\n",
    "| 41 &ndash; 45 | 45 |\n",
    "| 46 &ndash; 50 | 50 |\n",
    "| 51 &ndash; 58 | 58 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 1,\n",
       " 2: 2,\n",
       " 3: 3,\n",
       " 4: 4,\n",
       " 5: 5,\n",
       " 6: 6,\n",
       " 7: 7,\n",
       " 8: 8,\n",
       " 9: 9,\n",
       " 10: 10,\n",
       " 11: 11,\n",
       " 12: 12,\n",
       " 13: 13,\n",
       " 14: 14,\n",
       " 15: 15,\n",
       " 16: 16,\n",
       " 17: 17,\n",
       " 18: 18,\n",
       " 19: 19,\n",
       " 20: 20,\n",
       " 21: 21,\n",
       " 22: 22,\n",
       " 23: 23,\n",
       " 24: 24,\n",
       " 25: 25,\n",
       " 26: 26,\n",
       " 27: 27,\n",
       " 28: 28,\n",
       " 29: 29,\n",
       " 30: 30,\n",
       " 31: 31,\n",
       " 32: 32,\n",
       " 33: 33,\n",
       " 34: 34,\n",
       " 35: 35,\n",
       " 36: 36,\n",
       " 37: 37,\n",
       " 38: 38,\n",
       " 39: 39,\n",
       " 40: 40,\n",
       " 41: 45,\n",
       " 42: 45,\n",
       " 43: 45,\n",
       " 44: 45,\n",
       " 45: 45,\n",
       " 46: 50,\n",
       " 47: 50,\n",
       " 48: 50,\n",
       " 49: 50,\n",
       " 50: 50,\n",
       " 51: 58,\n",
       " 52: 58,\n",
       " 53: 58,\n",
       " 54: 58,\n",
       " 55: 58,\n",
       " 56: 58,\n",
       " 57: 58,\n",
       " 58: 58}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys_ = list(range(1, 59)) \n",
    "lens_ = list(range(1, 41)) + [45] * 5 + [50] * 5 + [58] * 8\n",
    "bucket_info = dict(zip(keys_, lens_))\n",
    "bucket_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Так же рассмотрим уникальные значения признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: pre_since_opened, unique values: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}\n",
      "Feature: pre_since_confirmed, unique values: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17}\n",
      "Feature: pre_pterm, unique values: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17}\n",
      "Feature: pre_fterm, unique values: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16}\n",
      "Feature: pre_till_pclose, unique values: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16}\n",
      "Feature: pre_till_fclose, unique values: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15}\n",
      "Feature: pre_loans_credit_limit, unique values: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}\n",
      "Feature: pre_loans_next_pay_summ, unique values: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Feature: pre_loans_outstanding, unique values: {1, 2, 3, 4, 5}\n",
      "Feature: pre_loans_total_overdue, unique values: {0, 1}\n",
      "Feature: pre_loans_max_overdue_sum, unique values: {0, 1, 2, 3}\n",
      "Feature: pre_loans_credit_cost_rate, unique values: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13}\n",
      "Feature: pre_loans5, unique values: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17}\n",
      "Feature: pre_loans530, unique values: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}\n",
      "Feature: pre_loans3060, unique values: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n",
      "Feature: pre_loans6090, unique values: {0, 1, 2, 3, 4, 5}\n",
      "Feature: pre_loans90, unique values: {1, 2, 3, 4, 8, 10, 11, 13, 14, 18, 19}\n",
      "Feature: is_zero_loans5, unique values: {0, 1}\n",
      "Feature: is_zero_loans530, unique values: {0, 1}\n",
      "Feature: is_zero_loans3060, unique values: {0, 1}\n",
      "Feature: is_zero_loans6090, unique values: {0, 1}\n",
      "Feature: is_zero_loans90, unique values: {0, 1}\n",
      "Feature: pre_util, unique values: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}\n",
      "Feature: pre_over2limit, unique values: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}\n",
      "Feature: pre_maxover2limit, unique values: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}\n",
      "Feature: is_zero_util, unique values: {0, 1}\n",
      "Feature: is_zero_over2limit, unique values: {0, 1}\n",
      "Feature: is_zero_maxover2limit, unique values: {0, 1}\n",
      "Feature: enc_paym_0, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_1, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_2, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_3, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_4, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_5, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_6, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_7, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_8, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_9, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_10, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_11, unique values: {1, 2, 3, 4}\n",
      "Feature: enc_paym_12, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_13, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_14, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_15, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_16, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_17, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_18, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_19, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_20, unique values: {1, 2, 3, 4}\n",
      "Feature: enc_paym_21, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_22, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_23, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_24, unique values: {1, 2, 3, 4}\n",
      "Feature: enc_loans_account_holder_type, unique values: {0, 1, 2, 3, 4, 5, 6}\n",
      "Feature: enc_loans_credit_status, unique values: {0, 1, 2, 3, 4, 5, 6}\n",
      "Feature: enc_loans_credit_type, unique values: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Feature: enc_loans_account_cur, unique values: {0, 1, 2, 3}\n",
      "Feature: pclose_flag, unique values: {0, 1}\n",
      "Feature: fclose_flag, unique values: {0, 1}\n"
     ]
    }
   ],
   "source": [
    "for feat, uniq in uniques.items():\n",
    "    print(f\"Feature: {feat}, unique values: {uniq}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Поскольку паддинг будет производиться нулями, а категориальные признаки закодированы, начиная с 0, перед паддингом будем сдвигать все значения на 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Вся описанная выше предобработка данных реализована в виде функции `create_buckets_from_credits`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_buckets_from_credits(path_to_dataset, bucket_info, save_to_path, frame_with_ids = None, \n",
    "                                num_parts_to_preprocess_at_once: int = 1, \n",
    "                                num_parts_total=50, has_target=False):\n",
    "    block = 0\n",
    "    for step in tqdm.notebook.tqdm(range(0, num_parts_total, num_parts_to_preprocess_at_once),\n",
    "                     desc=\"Preparing credit data\"):\n",
    "        credits_frame = read_parquet_dataset_from_local(path_to_dataset, step, num_parts_to_preprocess_at_once, verbose=True)\n",
    "        credits_frame.loc[:, features] += 1       \n",
    "        seq = transform_credits_to_sequences(credits_frame)\n",
    "        print(\"Transforming credits to sequences is done.\")\n",
    "        \n",
    "        if frame_with_ids is not None:\n",
    "            seq = seq.merge(frame_with_ids, on=\"id\")\n",
    "\n",
    "        block_as_str = str(block)\n",
    "        if len(block_as_str) == 1:\n",
    "            block_as_str = \"00\" + block_as_str\n",
    "        else:\n",
    "            block_as_str = \"0\" + block_as_str\n",
    "            \n",
    "        processed_fragment =  create_padded_buckets(seq, bucket_info=bucket_info, has_target=has_target, \n",
    "                                                    save_to_file_path=os.path.join(save_to_path, \n",
    "                                                                                   f\"processed_chunk_{block_as_str}.pkl\"))\n",
    "        block += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Разобьем обучающие данные на тренировочную и валидационную выборки. Воспользуемся самым простым способом &ndash; для валидации случайным образом выберем 10% обучающих данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2700000, 2), (300000, 2))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, val = train_test_split(train_target, random_state=42, test_size=0.1)\n",
    "train.shape, val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BUCKETS_PATH = \"../data/train_buckets_rnn\"\n",
    "VAL_BUCKETS_PATH = \"../data/val_buckets_rnn\"\n",
    "TEST_BUCKETS_PATH = \"../data/test_buckets_rnn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for buckets_path in [TRAIN_BUCKETS_PATH, VAL_BUCKETS_PATH, TEST_BUCKETS_PATH]:\n",
    "    !rm -rf $buckets_path\n",
    "    !mkdir $buckets_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1322f741137747f492ba9f9367b698c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preparing credit data:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunks:\n",
      "../data/train_data/train_data_0.pq\n",
      "../data/train_data/train_data_1.pq\n",
      "../data/train_data/train_data_2.pq\n",
      "../data/train_data/train_data_3.pq\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e7b7a67e7874ae3abf5b1a5608a62e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading dataset with pandas:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming credits to sequences is done.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f1b6b60f3df4f3184257e26da32306d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting buckets:   0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunks:\n",
      "../data/train_data/train_data_4.pq\n",
      "../data/train_data/train_data_5.pq\n",
      "../data/train_data/train_data_6.pq\n",
      "../data/train_data/train_data_7.pq\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30f743ce8e1b4d84914db93a7bcca162",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading dataset with pandas:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming credits to sequences is done.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "996c33986748404d9b053724585fe12a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting buckets:   0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunks:\n",
      "../data/train_data/train_data_8.pq\n",
      "../data/train_data/train_data_9.pq\n",
      "../data/train_data/train_data_10.pq\n",
      "../data/train_data/train_data_11.pq\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c87415c713324edcbb8034d76ff04e96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading dataset with pandas:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming credits to sequences is done.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f935f7b344784f558ac99484eb7f194c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting buckets:   0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14min, sys: 1min 51s, total: 15min 51s\n",
      "Wall time: 14min 55s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../data/train_buckets_rnn/processed_chunk_000.pkl',\n",
       " '../data/train_buckets_rnn/processed_chunk_001.pkl',\n",
       " '../data/train_buckets_rnn/processed_chunk_002.pkl']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "create_buckets_from_credits(TRAIN_DATA_PATH,\n",
    "                            bucket_info=bucket_info,\n",
    "                            save_to_path=TRAIN_BUCKETS_PATH,\n",
    "                            frame_with_ids=train,\n",
    "                            num_parts_to_preprocess_at_once=4, \n",
    "                            num_parts_total=12, has_target=True)\n",
    "\n",
    "dataset_train = sorted([os.path.join(TRAIN_BUCKETS_PATH, x) for x in os.listdir(TRAIN_BUCKETS_PATH)])\n",
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4184f59d5b04390ac8e8986d336f05c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preparing credit data:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunks:\n",
      "../data/train_data/train_data_0.pq\n",
      "../data/train_data/train_data_1.pq\n",
      "../data/train_data/train_data_2.pq\n",
      "../data/train_data/train_data_3.pq\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66733c57799247269cf4caa0efee0117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading dataset with pandas:   0%|          | 0/4 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming credits to sequences is done.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1bc9ab1d9a343cea397aa80b492d48f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting buckets:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunks:\n",
      "../data/train_data/train_data_4.pq\n",
      "../data/train_data/train_data_5.pq\n",
      "../data/train_data/train_data_6.pq\n",
      "../data/train_data/train_data_7.pq\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "680c6e27ee2d496ea79f4e23863528f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading dataset with pandas:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming credits to sequences is done.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05bf137a36d2430b99bb6ba7e4290f62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting buckets:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunks:\n",
      "../data/train_data/train_data_8.pq\n",
      "../data/train_data/train_data_9.pq\n",
      "../data/train_data/train_data_10.pq\n",
      "../data/train_data/train_data_11.pq\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68cfa0202aa64132aeb90d34428f5d59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading dataset with pandas:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming credits to sequences is done.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08bbca16cb3e43f782e1bcea6e14ec7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting buckets:   0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13min 28s, sys: 1min 15s, total: 14min 43s\n",
      "Wall time: 13min 53s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../data/val_buckets_rnn/processed_chunk_000.pkl',\n",
       " '../data/val_buckets_rnn/processed_chunk_001.pkl',\n",
       " '../data/val_buckets_rnn/processed_chunk_002.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "create_buckets_from_credits(TRAIN_DATA_PATH,\n",
    "                            bucket_info=bucket_info,\n",
    "                            save_to_path=VAL_BUCKETS_PATH,\n",
    "                            frame_with_ids=val,\n",
    "                            num_parts_to_preprocess_at_once=4, \n",
    "                            num_parts_total=12, has_target=True)\n",
    "\n",
    "dataset_val = sorted([os.path.join(VAL_BUCKETS_PATH, x) for x in os.listdir(VAL_BUCKETS_PATH)])\n",
    "dataset_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20ff114a04b84da78b420c0daaea999d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preparing credit data:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunks:\n",
      "../data/test_data/test_data_0.pq\n",
      "../data/test_data/test_data_1.pq\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab116f60cce04ebdaa9a9684bfd98704",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading dataset with pandas:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming credits to sequences is done.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e6b656c9bf74249a466cb453c845f5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting buckets:   0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 24s, sys: 14.4 s, total: 2min 38s\n",
      "Wall time: 2min 27s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../data/test_buckets_rnn/processed_chunk_000.pkl']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "create_buckets_from_credits(TEST_DATA_PATH,\n",
    "                            bucket_info=bucket_info,\n",
    "                            save_to_path=TEST_BUCKETS_PATH, num_parts_to_preprocess_at_once=2, \n",
    "                            num_parts_total=2)\n",
    "\n",
    "dataset_test = sorted([os.path.join(TEST_BUCKETS_PATH, x) for x in os.listdir(TEST_BUCKETS_PATH)])\n",
    "dataset_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Для создания модели будем использовать фреймворк `torch`. В нем есть все, чтобы писать произвольные сложные архитектуры и быстро экспериментировать. Для того, чтобы мониторить и логировать весь процесс во время обучения сетей, рекомендуется использовать надстройки над данным фреймворком, например, `lightning`.\n",
    "\n",
    "* В бейзлайне мы предлагаем базовые компоненты, чтобы можно было обучать нейронную сеть и отслеживать ее качество. Для этого вам предоставлены следующие функции:\n",
    "    * `data_generators.batches_generator` &ndash; функция-генератор, итеративно возвращает батчи, поддерживает батчи для `tensorflow.keras` и `torch.nn.Module` моделей. В зависимости от флага `is_train` может быть использована для генерации батчей на train/val/test стадии.\n",
    "    * функция `pytorch_training.train_epoch` &ndash; обучает модель одну эпоху.\n",
    "    * функция `pytorch_training.eval_model` &ndash; проверяет качество модели на отложенной выборке и возвращает roc_auc_score.\n",
    "    * функция `pytorch_training.inference` &ndash; делает предикты на новых данных и готовит фрейм для проверяющей системы.\n",
    "    * класс `training_aux.EarlyStopping` &ndash; реализует early_stopping, сохраняя лучшую модель. Пример использования приведен ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_generators import batches_generator\n",
    "from pytorch_training import train_epoch, eval_model, inference\n",
    "from training_aux import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Все признаки, описывающие кредитную историю клиентов &ndash; категориальные. Для их представления в модели используем категориальные эмбеддинги. Для этого нужно каждому категориальному признаку задать размерность латентного пространства. Используем [формулу](https://forums.fast.ai/t/size-of-embedding-for-categorical-variables/42608) из библиотеки `fast.ai`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_embed_dim(n_cat: int) -> int:\n",
    "    return min(600, round(1.6 * n_cat**0.56))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pre_since_opened': (20, 9),\n",
       " 'pre_since_confirmed': (18, 8),\n",
       " 'pre_pterm': (18, 8),\n",
       " 'pre_fterm': (17, 8),\n",
       " 'pre_till_pclose': (17, 8),\n",
       " 'pre_till_fclose': (16, 8),\n",
       " 'pre_loans_credit_limit': (20, 9),\n",
       " 'pre_loans_next_pay_summ': (8, 5),\n",
       " 'pre_loans_outstanding': (6, 4),\n",
       " 'pre_loans_total_overdue': (2, 2),\n",
       " 'pre_loans_max_overdue_sum': (4, 3),\n",
       " 'pre_loans_credit_cost_rate': (14, 7),\n",
       " 'pre_loans5': (18, 8),\n",
       " 'pre_loans530': (20, 9),\n",
       " 'pre_loans3060': (10, 6),\n",
       " 'pre_loans6090': (6, 4),\n",
       " 'pre_loans90': (20, 9),\n",
       " 'is_zero_loans5': (2, 2),\n",
       " 'is_zero_loans530': (2, 2),\n",
       " 'is_zero_loans3060': (2, 2),\n",
       " 'is_zero_loans6090': (2, 2),\n",
       " 'is_zero_loans90': (2, 2),\n",
       " 'pre_util': (20, 9),\n",
       " 'pre_over2limit': (20, 9),\n",
       " 'pre_maxover2limit': (20, 9),\n",
       " 'is_zero_util': (2, 2),\n",
       " 'is_zero_over2limit': (2, 2),\n",
       " 'is_zero_maxover2limit': (2, 2),\n",
       " 'enc_paym_0': (4, 3),\n",
       " 'enc_paym_1': (4, 3),\n",
       " 'enc_paym_2': (4, 3),\n",
       " 'enc_paym_3': (4, 3),\n",
       " 'enc_paym_4': (4, 3),\n",
       " 'enc_paym_5': (4, 3),\n",
       " 'enc_paym_6': (4, 3),\n",
       " 'enc_paym_7': (4, 3),\n",
       " 'enc_paym_8': (4, 3),\n",
       " 'enc_paym_9': (4, 3),\n",
       " 'enc_paym_10': (4, 3),\n",
       " 'enc_paym_11': (5, 4),\n",
       " 'enc_paym_12': (4, 3),\n",
       " 'enc_paym_13': (4, 3),\n",
       " 'enc_paym_14': (4, 3),\n",
       " 'enc_paym_15': (4, 3),\n",
       " 'enc_paym_16': (4, 3),\n",
       " 'enc_paym_17': (4, 3),\n",
       " 'enc_paym_18': (4, 3),\n",
       " 'enc_paym_19': (4, 3),\n",
       " 'enc_paym_20': (5, 4),\n",
       " 'enc_paym_21': (4, 3),\n",
       " 'enc_paym_22': (4, 3),\n",
       " 'enc_paym_23': (4, 3),\n",
       " 'enc_paym_24': (5, 4),\n",
       " 'enc_loans_account_holder_type': (7, 5),\n",
       " 'enc_loans_credit_status': (7, 5),\n",
       " 'enc_loans_credit_type': (8, 5),\n",
       " 'enc_loans_account_cur': (4, 3),\n",
       " 'pclose_flag': (2, 2),\n",
       " 'fclose_flag': (2, 2)}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_projections = {feat: (max(uniq)+1, compute_embed_dim(max(uniq)+1)) for feat, uniq in uniques.items()}\n",
    "embedding_projections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Реализуем модель. Все входные признаки представим в виде эмбеддингов, сконкатенируем, чтобы получить векторное представление транзакции. Подадим последовательности в `GRU` рекуррентный слой. Используем последнее скрытое состояние в качестве выхода слоя. На основе такого входа построим небольшой `MLP`, выступающий классификатором для целевой задачи. Используем градиентный спуск, чтобы решить оптимизационную задачу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreditsRNN(nn.Module):\n",
    "    def __init__(self, features, embedding_projections, rnn_units=128, top_classifier_units=32):\n",
    "        super(CreditsRNN, self).__init__()\n",
    "        self._credits_cat_embeddings = nn.ModuleList([self._create_embedding_projection(*embedding_projections[feature]) \n",
    "                                                          for feature in features])\n",
    "                        \n",
    "        self._gru = nn.GRU(input_size=sum([embedding_projections[x][1] for x in features]),\n",
    "                             hidden_size=rnn_units, batch_first=True, bidirectional=False)\n",
    "        self._hidden_size = rnn_units\n",
    "        self._top_classifier = nn.Linear(in_features=rnn_units, out_features=top_classifier_units)\n",
    "        self._intermediate_activation = nn.ReLU()\n",
    "        self._head = nn.Linear(in_features=top_classifier_units, out_features=1)\n",
    "    \n",
    "    def forward(self, features):\n",
    "        batch_size = features[0].shape[0]\n",
    "        embeddings = [embedding(features[i]) for i, embedding in enumerate(self._credits_cat_embeddings)]\n",
    "        concated_embeddings = torch.cat(embeddings, dim=-1)\n",
    "        \n",
    "        _, last_hidden = self._gru(concated_embeddings)\n",
    "        last_hidden = torch.reshape(last_hidden.permute(1, 2, 0), shape=(batch_size, self._hidden_size))\n",
    "                                \n",
    "        classification_hidden = self._top_classifier(last_hidden)\n",
    "        activation = self._intermediate_activation(classification_hidden)\n",
    "        raw_output = self._head(activation)\n",
    "        return raw_output\n",
    "    \n",
    "    @classmethod\n",
    "    def _create_embedding_projection(cls, cardinality, embed_size, add_missing=True, padding_idx=0):\n",
    "        add_missing = 1 if add_missing else 0\n",
    "        return nn.Embedding(num_embeddings=cardinality+add_missing, embedding_dim=embed_size, padding_idx=padding_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./checkpoints/\n",
    "!mkdir ./checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove ‘./checkpoints/pytorch_baseline’: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!rm -r ./checkpoints/pytorch_baseline\n",
    "!mkdir ./checkpoints/pytorch_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Для того, чтобы детектировать переобучение используем EarlyStopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_checkpoints = \"./checkpoints/pytorch_baseline/\"\n",
    "es = EarlyStopping(patience=3, mode=\"max\", verbose=True, save_path=os.path.join(path_to_checkpoints, \"best_checkpoint.pt\"), \n",
    "                   metric_name=\"ROC-AUC\", save_format=\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "train_batch_size = 128\n",
    "val_batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CreditsRNN(features, embedding_projections).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditsRNN(\n",
       "  (_credits_cat_embeddings): ModuleList(\n",
       "    (0): Embedding(21, 9, padding_idx=0)\n",
       "    (1): Embedding(19, 8, padding_idx=0)\n",
       "    (2): Embedding(19, 8, padding_idx=0)\n",
       "    (3): Embedding(18, 8, padding_idx=0)\n",
       "    (4): Embedding(18, 8, padding_idx=0)\n",
       "    (5): Embedding(17, 8, padding_idx=0)\n",
       "    (6): Embedding(21, 9, padding_idx=0)\n",
       "    (7): Embedding(9, 5, padding_idx=0)\n",
       "    (8): Embedding(7, 4, padding_idx=0)\n",
       "    (9): Embedding(3, 2, padding_idx=0)\n",
       "    (10): Embedding(5, 3, padding_idx=0)\n",
       "    (11): Embedding(15, 7, padding_idx=0)\n",
       "    (12): Embedding(19, 8, padding_idx=0)\n",
       "    (13): Embedding(21, 9, padding_idx=0)\n",
       "    (14): Embedding(11, 6, padding_idx=0)\n",
       "    (15): Embedding(7, 4, padding_idx=0)\n",
       "    (16): Embedding(21, 9, padding_idx=0)\n",
       "    (17): Embedding(3, 2, padding_idx=0)\n",
       "    (18): Embedding(3, 2, padding_idx=0)\n",
       "    (19): Embedding(3, 2, padding_idx=0)\n",
       "    (20): Embedding(3, 2, padding_idx=0)\n",
       "    (21): Embedding(3, 2, padding_idx=0)\n",
       "    (22): Embedding(21, 9, padding_idx=0)\n",
       "    (23): Embedding(21, 9, padding_idx=0)\n",
       "    (24): Embedding(21, 9, padding_idx=0)\n",
       "    (25): Embedding(3, 2, padding_idx=0)\n",
       "    (26): Embedding(3, 2, padding_idx=0)\n",
       "    (27): Embedding(3, 2, padding_idx=0)\n",
       "    (28): Embedding(5, 3, padding_idx=0)\n",
       "    (29): Embedding(5, 3, padding_idx=0)\n",
       "    (30): Embedding(5, 3, padding_idx=0)\n",
       "    (31): Embedding(5, 3, padding_idx=0)\n",
       "    (32): Embedding(5, 3, padding_idx=0)\n",
       "    (33): Embedding(5, 3, padding_idx=0)\n",
       "    (34): Embedding(5, 3, padding_idx=0)\n",
       "    (35): Embedding(5, 3, padding_idx=0)\n",
       "    (36): Embedding(5, 3, padding_idx=0)\n",
       "    (37): Embedding(5, 3, padding_idx=0)\n",
       "    (38): Embedding(5, 3, padding_idx=0)\n",
       "    (39): Embedding(6, 4, padding_idx=0)\n",
       "    (40): Embedding(5, 3, padding_idx=0)\n",
       "    (41): Embedding(5, 3, padding_idx=0)\n",
       "    (42): Embedding(5, 3, padding_idx=0)\n",
       "    (43): Embedding(5, 3, padding_idx=0)\n",
       "    (44): Embedding(5, 3, padding_idx=0)\n",
       "    (45): Embedding(5, 3, padding_idx=0)\n",
       "    (46): Embedding(5, 3, padding_idx=0)\n",
       "    (47): Embedding(5, 3, padding_idx=0)\n",
       "    (48): Embedding(6, 4, padding_idx=0)\n",
       "    (49): Embedding(5, 3, padding_idx=0)\n",
       "    (50): Embedding(5, 3, padding_idx=0)\n",
       "    (51): Embedding(5, 3, padding_idx=0)\n",
       "    (52): Embedding(6, 4, padding_idx=0)\n",
       "    (53): Embedding(8, 5, padding_idx=0)\n",
       "    (54): Embedding(8, 5, padding_idx=0)\n",
       "    (55): Embedding(9, 5, padding_idx=0)\n",
       "    (56): Embedding(5, 3, padding_idx=0)\n",
       "    (57): Embedding(3, 2, padding_idx=0)\n",
       "    (58): Embedding(3, 2, padding_idx=0)\n",
       "  )\n",
       "  (_gru): GRU(258, 128, batch_first=True)\n",
       "  (_top_classifier): Linear(in_features=128, out_features=32, bias=True)\n",
       "  (_intermediate_activation): ReLU()\n",
       "  (_head): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(lr=1e-3, params=model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Запустим цикл обучения, каждую эпоху будем логировать лосс, а так же ROC-AUC на валидации и на обучении. Будем сохрнаять веса после каждой эпохи, а так же лучшие с помощью early_stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f2e04ae36f84c9dbd6c73067d3c5bb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss after epoch: 0.13714173436164856\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7ef4510ad354f04b9dc5555b6fc7841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating model: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation ROC-AUC improved (-inf --> 0.770302).  Saving model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9612815dee1d4b3fbce5fb7a51c3d532",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating model: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed. Train ROC AUC: 0.7734998067343924, val ROC AUC: 0.7703019844426466\n",
      "Starting epoch 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21f94f0964df43fbb90d39c4236f9259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss after epoch: 0.13469769060611725\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a886713c6644c8d92a253c171476639",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating model: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No imporvement in validation ROC-AUC. Current: 0.766447. Current best: 0.770302\n",
      "EarlyStopping counter: 1 out of 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d698c7e23c72416c86f7b065d08c2cdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating model: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 completed. Train ROC AUC: 0.7727527842844606, val ROC AUC: 0.7664471490493795\n",
      "Starting epoch 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cad474233adb4ce7a68ca5bceb315a1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss after epoch: 0.13397285342216492\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c43f93fc1dc6405ebe055ad04fda42cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating model: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation ROC-AUC improved (0.770302 --> 0.771808).  Saving model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cf71466cf1149edb26c81ceb1df2055",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating model: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 completed. Train ROC AUC: 0.7825243788851524, val ROC AUC: 0.7718082173649778\n",
      "Starting epoch 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1edf2aa33b9d470ebfc8fa0fbc448734",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss after epoch: 0.13339394330978394\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1be67cde1084ebf86f82b051fdc6576",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating model: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation ROC-AUC improved (0.771808 --> 0.773365).  Saving model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "148a93962e564aaf8e41eb4ca59584c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating model: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 completed. Train ROC AUC: 0.7848280528647544, val ROC AUC: 0.7733650500825249\n",
      "Starting epoch 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73e4ab4fd76d4bcb83358f34893e0bf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss after epoch: 0.13292144238948822\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c0ebd97e4c24831bf8275a33db734b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating model: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation ROC-AUC improved (0.773365 --> 0.774036).  Saving model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcecbd8c5c4c4416b7400ba552e1283b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating model: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 completed. Train ROC AUC: 0.7908206665940005, val ROC AUC: 0.7740358627738797\n",
      "Starting epoch 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "964f7efb839a4b14bcd33732861155fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss after epoch: 0.13214239478111267\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9952b16b1cc44f6c9925a270cbc21aa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating model: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No imporvement in validation ROC-AUC. Current: 0.769683. Current best: 0.774036\n",
      "EarlyStopping counter: 1 out of 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0feae3fad90474e860c351cd322eded",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating model: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 completed. Train ROC AUC: 0.7907965721505504, val ROC AUC: 0.7696828966694768\n",
      "Starting epoch 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bca19662484648dcbb1e7e20b4c80c63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss after epoch: 0.13188329339027405\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc02dca81e744b1faad1e843b7459ba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating model: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No imporvement in validation ROC-AUC. Current: 0.770388. Current best: 0.774036\n",
      "EarlyStopping counter: 2 out of 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a9f92329b13439cb55b35b8c13324d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating model: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 completed. Train ROC AUC: 0.7934537008682312, val ROC AUC: 0.7703882952635871\n",
      "Starting epoch 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c00a4b969c624df19fee1a24c8b02c86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss after epoch: 0.13135059177875523\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "329346fbc72f474192585d7ba9686813",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating model: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No imporvement in validation ROC-AUC. Current: 0.770582. Current best: 0.774036\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping reached. Stop training...\n",
      "CPU times: user 1h 4min 3s, sys: 4min 12s, total: 1h 8min 16s\n",
      "Wall time: 1h 8min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Starting epoch {epoch+1}\")\n",
    "    train_epoch(model, optimizer, dataset_train, batch_size=train_batch_size, \n",
    "                shuffle=True, print_loss_every_n_batches=500, device=device)\n",
    "    \n",
    "    val_roc_auc = eval_model(model, dataset_val, batch_size=val_batch_size, device=device)\n",
    "    es(val_roc_auc, model)\n",
    "    \n",
    "    if es.early_stop:\n",
    "        print(\"Early stopping reached. Stop training...\")\n",
    "        break\n",
    "    torch.save(model.state_dict(), os.path.join(path_to_checkpoints, f\"epoch_{epoch+1}_val_{val_roc_auc:.3f}.pt\"))\n",
    "    \n",
    "    train_roc_auc = eval_model(model, dataset_train, batch_size=val_batch_size, device=device)\n",
    "    print(f\"Epoch {epoch+1} completed. Train ROC AUC: {train_roc_auc}, val ROC AUC: {val_roc_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Подготовим посылку в проверяющую систему"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(os.path.join(path_to_checkpoints, \"best_checkpoint.pt\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a839076524ab404c93da47ad82e051b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test predictions: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_preds = inference(model, dataset_test, batch_size=128, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3000014</td>\n",
       "      <td>-2.655329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3000020</td>\n",
       "      <td>-1.603065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3000027</td>\n",
       "      <td>-2.760454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3000043</td>\n",
       "      <td>-1.486076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3000049</td>\n",
       "      <td>-3.119595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id     score\n",
       "0  3000014 -2.655329\n",
       "1  3000020 -1.603065\n",
       "2  3000027 -2.760454\n",
       "3  3000043 -1.486076\n",
       "4  3000049 -3.119595"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500000, 2)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds.to_csv(\"torch_submission.csv\", index=None) # ~ 0.765 на public test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
